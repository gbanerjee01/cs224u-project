{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "infinite-sequence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import wandb\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "import numpy as np\n",
    "import fastwer\n",
    "\n",
    "import pandas as pd\n",
    "from simpletransformers.seq2seq import (\n",
    "    Seq2SeqModel,\n",
    "    Seq2SeqArgs,\n",
    ")\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model_args = Seq2SeqArgs()\n",
    "model_args.num_train_epochs = 15\n",
    "# model_args.no_save = True\n",
    "model_args.evaluate_generated_text = True\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.evaluate_during_training_verbose = False\n",
    "model_args.tensorboard_dir = \"runs\"\n",
    "model_args.max_length = 200\n",
    "model_args.train_batch_size=15\n",
    "model_args.overwrite_output_dir=True\n",
    "model_args.wandb_project = \"cs224u\"\n",
    "\n",
    "# Initialize model\n",
    "model = Seq2SeqModel(\n",
    "    encoder_decoder_type=\"bart\",\n",
    "    encoder_decoder_name=\"facebook/bart-large-cnn\",\n",
    "    args=model_args,\n",
    "    use_cuda=True,\n",
    ")\n",
    "\n",
    "# model = Seq2SeqModel(encoder_decoder_type=\"bart\", encoder_decoder_name=\"./outputs/best_model\", args=model_args, use_cuda=True,)\n",
    "\n",
    "# model = Seq2SeqModel(\n",
    "#     encoder_type=\"bert\",\n",
    "#     encoder_name=\"bert-base-uncased\",\n",
    "#     decoder_name=\"bert-base-uncased\",\n",
    "#     args=model_args,\n",
    "#     use_cuda=True,\n",
    "# )\n",
    "\n",
    "\n",
    "def count_matches(labels, preds):\n",
    "    return sum(\n",
    "        [\n",
    "            1 if label == pred else 0\n",
    "            for label, pred in zip(labels, preds)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_wer(labels, preds):\n",
    "    return np.mean(\n",
    "        [\n",
    "            fastwer.score_sent(pred, label)\n",
    "            for label, pred in zip(labels, preds)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enormous-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_pickle(\"train.pkl\")\n",
    "train_df = train_df.dropna()\n",
    "dev_df = pd.read_pickle(\"dev.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "settled-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brutal-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_df = dev_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dying-catholic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.seq2seq.seq2seq_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4eaa14ab0034ac09fbd85ad71d93f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16163.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.seq2seq.seq2seq_model: Training started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd449bce41948dc9ffe91facf72900d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=15.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgbanerje\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rich-eon-132</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/gbanerje/cs224u\" target=\"_blank\">https://wandb.ai/gbanerje/cs224u</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/gbanerje/cs224u/runs/11ezftyt\" target=\"_blank\">https://wandb.ai/gbanerje/cs224u/runs/11ezftyt</a><br/>\n",
       "                Run data is saved locally in <code>/data/cs224u-project/s2s/bart-cnn/wandb/run-20210602_100914-11ezftyt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccf312d657248bb9245efb6ac6ff241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 15', max=1078.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b5197bfa6aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m model.train_model(\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount_matches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_wer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_running_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'fp16'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/simpletransformers/seq2seq/seq2seq_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0meval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         )\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/simpletransformers/seq2seq/seq2seq_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, output_dir, show_running_loss, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m                     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# wandb.init(project='cs224u', entity='gbanerje')\n",
    "\n",
    "# # 2. Save model inputs and hyperparameters\n",
    "# config = wandb.config\n",
    "# config.learning_rate = 0.01\n",
    "\n",
    "# Model training here\n",
    "\n",
    "model.train_model(\n",
    "    train_df, eval_data=dev_df, matches=count_matches, wer=get_wer, show_running_loss=True, args={'fp16': False}\n",
    ")\n",
    "\n",
    "# wandb.join()\n",
    "\n",
    "# # Evaluate the model\n",
    "results = model.eval_model(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "monthly-nightlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9096c815e1254aceb597a8169153cf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating outputs', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Hee walks dogks. He walks dog. He walked dogks, he walks dogk. He was walking dogks? He walks dogs. He's walking dogk? He walked dogs. he walks dogs? He's not\",\n",
       " \"Hai my precous boi. I'm not sure what to do. I've got a plan. I'll be back. I hope. I love you. I really do. But I'm a little nervous. I don\",\n",
       " 'Tteko is a national program of the Togo Football Association. The team is based in the city of Tteko. The club has been in business since the 1970s. The organization has been around for more than 30 years',\n",
       " 'The trade often coing sides with other traes. The trade often trade often with other trade often. The traes are often on opposite sides of the war. The war has been going on for years. The two sides trade often',\n",
       " 'He kept extensive nodes on a cosing playurs. He kept them on a number of different nodes. He also kept them in a number on a different part of the building. He had a lot of nodes on the building, he']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "        [\n",
    "            \"Hee walks dogks\", \"Hai my precous boi\", \"tteko\", \"e trade often coing sides with other traes\", \"he kepts extensive nodes on a cosing playurs\"\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unsigned-spanking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the coma sat to te parnting afternoon and the ...</td>\n",
       "      <td>Takuma Sato's disappointing afternoon ended wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leat remark many has fhurtorexxpended to inclu...</td>\n",
       "      <td>Tony Roma's menu has further expanded to inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is nobody that's rich and stupid and not...</td>\n",
       "      <td>There's nobody that rich and stupid and narcis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e trade often coing sides with other traes wit...</td>\n",
       "      <td>The trail often coincides with other trails wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he kepts extensive nodes on a cosing playurs i...</td>\n",
       "      <td>He kept extensive notes on opposing players an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  the coma sat to te parnting afternoon and the ...   \n",
       "1  leat remark many has fhurtorexxpended to inclu...   \n",
       "2  there is nobody that's rich and stupid and not...   \n",
       "3  e trade often coing sides with other traes wit...   \n",
       "4  he kepts extensive nodes on a cosing playurs i...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Takuma Sato's disappointing afternoon ended wi...  \n",
       "1  Tony Roma's menu has further expanded to inclu...  \n",
       "2  There's nobody that rich and stupid and narcis...  \n",
       "3  The trail often coincides with other trails wi...  \n",
       "4  He kept extensive notes on opposing players an...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indie-combine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb57d8d04c64b24bb4af8e57acf9e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating outputs', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hee woks!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "        [\n",
    "            \"Hee woks dogks\"\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "passing-venezuela",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<simpletransformers.seq2seq.seq2seq_model.Seq2SeqModel at 0x7f95b0f93d50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-junior",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
